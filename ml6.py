# -*- coding: utf-8 -*-
"""ml6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FLNjFZeVbsyWAVcLw-6GbtPqGbFEDa4U
"""

# ==========================================================
# NaÃ¯ve Bayes Classification from Scratch
# Dataset: Iris (auto loaded from sklearn)
# Output: Confusion Matrix + Accuracy
# ==========================================================

import math
import random
from sklearn.datasets import load_iris
from sklearn.metrics import confusion_matrix, accuracy_score

# ----------------------------------------------------------
# 1. Load Dataset
# ----------------------------------------------------------
def load_dataset():
    iris = load_iris()
    X = iris.data
    y = iris.target

    dataset = []
    for i in range(len(X)):
        dataset.append(list(X[i]) + [y[i]])
    return dataset

# ----------------------------------------------------------
# 2. Train-Test Split
# ----------------------------------------------------------
def train_test_split(dataset, test_ratio=0.3):
    random.shuffle(dataset)
    split_index = int(len(dataset) * (1 - test_ratio))
    return dataset[:split_index], dataset[split_index:]

# ----------------------------------------------------------
# 3. Separate dataset by class
# ----------------------------------------------------------
def separate_by_class(dataset):
    separated = {}
    for row in dataset:
        class_value = row[-1]
        if class_value not in separated:
            separated[class_value] = []
        separated[class_value].append(row)
    return separated

# ----------------------------------------------------------
# 4. Mean and Standard Deviation
# ----------------------------------------------------------
def mean(numbers):
    return sum(numbers) / float(len(numbers))

def stdev(numbers):
    avg = mean(numbers)
    variance = sum((x - avg) ** 2 for x in numbers) / float(len(numbers) - 1)
    return math.sqrt(variance)

# ----------------------------------------------------------
# 5. Summarize dataset (mean, std for each feature)
# ----------------------------------------------------------
def summarize_dataset(dataset):
    summaries = [(mean(column), stdev(column))
                 for column in zip(*dataset)]
    del summaries[-1]  # remove class column
    return summaries

def summarize_by_class(dataset):
    separated = separate_by_class(dataset)
    summaries = {}
    for class_value, rows in separated.items():
        summaries[class_value] = summarize_dataset(rows)
    return summaries

# ----------------------------------------------------------
# 6. Gaussian Probability Density Function
# ----------------------------------------------------------
def gaussian_probability(x, mean, stdev):
    exponent = math.exp(-((x - mean) ** 2 / (2 * stdev ** 2)))
    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent

# ----------------------------------------------------------
# 7. Calculate Class Probabilities
# ----------------------------------------------------------
def calculate_class_probabilities(summaries, row):
    total_rows = sum(len(summaries[label]) for label in summaries)
    probabilities = {}

    for class_value, class_summaries in summaries.items():
        probabilities[class_value] = 1
        for i in range(len(class_summaries)):
            mean_, stdev_ = class_summaries[i]
            x = row[i]
            probabilities[class_value] *= gaussian_probability(x, mean_, stdev_)
    return probabilities

# ----------------------------------------------------------
# 8. Predict class
# ----------------------------------------------------------
def predict(summaries, row):
    probabilities = calculate_class_probabilities(summaries, row)
    best_label, best_prob = None, -1
    for class_value, probability in probabilities.items():
        if best_label is None or probability > best_prob:
            best_prob = probability
            best_label = class_value
    return best_label

def get_predictions(summaries, test_set):
    predictions = []
    for row in test_set:
        predictions.append(predict(summaries, row))
    return predictions

# ----------------------------------------------------------
# 9. MAIN PROGRAM
# ----------------------------------------------------------
def main():
    dataset = load_dataset()
    train_set, test_set = train_test_split(dataset, 0.3)

    # Train model
    summaries = summarize_by_class(train_set)

    # Test model
    test_features = [row[:-1] for row in test_set]
    actual_labels = [row[-1] for row in test_set]
    predictions = get_predictions(summaries, test_features)

    # Confusion Matrix & Accuracy
    cm = confusion_matrix(actual_labels, predictions)
    acc = accuracy_score(actual_labels, predictions)

    print("\nPredicted Labels:", predictions)
    print("Actual Labels:", actual_labels)

    print("\nConfusion Matrix:\n", cm)
    print("\nAccuracy: {:.2f}%".format(acc * 100))

# Run program
if __name__ == "__main__":
    main()