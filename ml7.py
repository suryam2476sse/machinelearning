# -*- coding: utf-8 -*-
"""ml7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1urJDCrWUKfvR1DdoT2VS0uuphkHRm74o
"""

# Logistic Regression From Scratch (No CSV Required)

import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# --------------------------------------------------
# 1. Load Built-in Dataset (Binary classification)
# --------------------------------------------------
data = load_breast_cancer()
X = data.data
y = data.target

# Normalize features
X = (X - X.mean(axis=0)) / X.std(axis=0)

# Add bias column
X = np.c_[np.ones(X.shape[0]), X]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# --------------------------------------------------
# 2. Sigmoid Function
# --------------------------------------------------
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# --------------------------------------------------
# 3. Cost Function
# --------------------------------------------------
def compute_cost(X, y, weights):
    m = len(y)
    predictions = sigmoid(X @ weights)
    cost = -(1/m) * np.sum(y*np.log(predictions) + (1-y)*np.log(1-predictions))
    return cost

# --------------------------------------------------
# 4. Gradient Descent Training
# --------------------------------------------------
def train_logistic_regression(X, y, lr=0.01, iterations=1000):
    m, n = X.shape
    weights = np.zeros(n)

    for i in range(iterations):
        predictions = sigmoid(X @ weights)
        gradient = (1/m) * (X.T @ (predictions - y))
        weights -= lr * gradient

        if i % 100 == 0:
            print(f"Iteration {i} | Cost: {compute_cost(X, y, weights):.4f}")

    return weights

# Train model
weights = train_logistic_regression(X_train, y_train)

# --------------------------------------------------
# 5. Prediction
# --------------------------------------------------
def predict(X, weights):
    probs = sigmoid(X @ weights)
    return (probs >= 0.5).astype(int)

y_pred = predict(X_test, weights)

# --------------------------------------------------
# 6. Accuracy & Confusion Matrix
# --------------------------------------------------
accuracy = np.mean(y_pred == y_test) * 100
print("\nModel Accuracy:", round(accuracy, 2), "%")

TP = np.sum((y_test == 1) & (y_pred == 1))
TN = np.sum((y_test == 0) & (y_pred == 0))
FP = np.sum((y_test == 0) & (y_pred == 1))
FN = np.sum((y_test == 1) & (y_pred == 0))

print("\nConfusion Matrix")
print("TP:", TP, "FP:", FP)
print("FN:", FN, "TN:", TN)